# 多层感知机

## 简介

> 这一部分的内容在李宏毅的课程有所涉及

mlp 的输出结果是一个类别（例如 0/1, +1/-1），相比较之下，linear 输出的是实数，softmax 输出的是概率

单层的感知机是不可以实现 XOR 的分类的，所以要使用多层感知机，  $ \sigma$ 代表激活函数
$$
\mathbf{h}^{(l)} = \sigma\left( W^{(l)} \mathbf{h}^{(l-1)} + \mathbf{b}^{(l)} \right)
$$


### 隐藏层

隐藏层不可以是线性的，因为多层的线性都可使用一个线性层代表，所以我们要应用非线性函数（称为激活函数）

常见的激活函数有以下几种：

1. Sigmoid: $\sigma(x)=\frac{1}{1+e^{-x}}$

2. Tanh: $\tanh(x)=\frac{e^x - e^{-x}}{e^x + e^{-x}}$
3. ReLU (Rectified Linear Unit): $\text{ReLU}(x)=\max(0,x)$
4. PReLU (Parametric ~):  $f(x)= \begin{cases} x, & x \ge 0 \\ a x, & x < 0 \end{cases}$

其中 ReLU 相对常用，并且计算非常的快，前两个容易梯度消失

### 输出层

在多类分类中，我们需要将输出层的数量更改到分类的数量，所以使用 softmax 来作为输出层，如下图所示

<img src="https://blog-picgo-rainerseventeen.oss-cn-shanghai.aliyuncs.com/blog/202511301929962.svg" style="zoom:150%;" />