# 深度学习计算

## 层和块

实际上就是讲解了如何使用 pytorch 中的 `nn.module` 以及 `nn.Sequential` 这两个模块

这一部分内容已经在 pytorch 学习中涉及过，这里不再赘述

## 参数管理

module 的每一个网络都是类似于一个 list 的方式排列的，所以

1. 通过层进行访问

```python
import torch
form torch import nn
net = ... # 某一个 nn.module

print(net[2].state_dict()) # 拿到一个层的详细数据
print(net[2].bias) 	# 拿到某一个层的某一个具体的数据
```

2. 参数初始化

可以通过`apply` 的方法来执行自定义初始化，也可以用官方的方法执行初始化

```python
def init_normal(m):
    if type(m) == nn.Linear:
        nn.init.normal_(m.weight, mean=0, std=0.01)	# 对 weight 执行正态分布初始化
        nn.init_zeros_(m.bias)	# 对 bias 执行全部为 0
net.apply(init_normal)
print(net[0].weight.data[0], net[0].bias.data[0])
```

3. 参数绑定

对于希望在多个层之间进行共享参数，可以用参数绑定的形式，使用同一个共享层

```python
shared = nn.Linear(8, 8)
net = nn.Sequential(
	nn.Linear(4, 8), nn.ReLU(),
    shared, nn.ReLU(),
    shared, nn.ReLU(), # 这两个层的参数是一样的
    nn.Linear(8, 1)
)

print(net[2].weight.data is net[4].weight.data) # 实际上是同一个对象
```

